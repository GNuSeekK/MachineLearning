{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "주식 데이터 인공지능 학습 모델.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP+kpovToiwOhFMPqLv/Xsy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GNuSeekK/MachineLearning/blob/main/%EC%A3%BC%EC%8B%9D_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5_%ED%95%99%EC%8A%B5_%EB%AA%A8%EB%8D%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELaWT7MMQvxd"
      },
      "source": [
        "# 구글 드라이브 Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfnPcpS7Q5Nq",
        "outputId": "28a1d147-ac43-4f2b-c675-331184d07150"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyLZ6_DKRKl6"
      },
      "source": [
        "# Frame_work import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m8m2WlvfRGeC",
        "outputId": "f7dabbdf-289f-4cd8-bd41-731fa7656e9a"
      },
      "source": [
        "!pip install cryptography\n",
        "!pip install pymysql\n",
        "!pip install --upgrade pandas_profiling\n",
        " \n",
        "#드라이브 마운트\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense, Activation\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import os, sys\n",
        "import pymysql\n",
        "import cryptography\n",
        "import datetime as dt\n",
        "import pandas_profiling\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import multiprocessing as mp\n",
        "from multiprocessing import Pool, Manager"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.7/dist-packages (3.4.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography) (2.20)\n",
            "Requirement already satisfied: pymysql in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Collecting pandas_profiling\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/a3/34519d16e5ebe69bad30c5526deea2c3912634ced7f9b5e6e0bb9dbbd567/pandas_profiling-3.0.0-py2.py3-none-any.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from pandas_profiling) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: seaborn>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from pandas_profiling) (0.11.1)\n",
            "Collecting htmlmin>=0.1.12\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Collecting PyYAML>=5.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 9.8MB/s \n",
            "\u001b[?25hCollecting phik>=0.11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/ce/193e8ddf62d4be643b9b4b20e8e9c63b2f6a20f92778c0410c629f89bdaa/phik-0.11.2.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 17.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from pandas_profiling) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from pandas_profiling) (1.0.1)\n",
            "Collecting requests>=2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.9MB/s \n",
            "\u001b[?25hCollecting tangled-up-in-unicode==0.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/3e/cb354fb2097fcf2fd5b5a342b10ae2a6e9363ba435b64e3e00c414064bc7/tangled_up_in_unicode-0.1.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 22.5MB/s \n",
            "\u001b[?25hCollecting visions[type_image_path]==0.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/96/01e4ba22cef96ae5035dbcf0451c2f4f859f8f17393b98406b23f0034279/visions-0.7.1-py3-none-any.whl (102kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 51.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from pandas_profiling) (1.19.5)\n",
            "Collecting tqdm>=4.48.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/8a/34efae5cf9924328a8f34eeb2fdaae14c011462d9f0e3fcded48e1266d1c/tqdm-4.60.0-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in /usr/local/lib/python3.7/dist-packages (from pandas_profiling) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: missingno>=0.4.2 in /usr/local/lib/python3.7/dist-packages (from pandas_profiling) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: jinja2>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas_profiling) (2.11.3)\n",
            "Collecting pydantic>=1.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/f2/2d5425efe57f6c4e06cbe5e587c1fd16929dcf0eb90bd4d3d1e1c97d1151/pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->pandas_profiling) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->pandas_profiling) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->pandas_profiling) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->pandas_profiling) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas_profiling) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas_profiling) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas_profiling) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas_profiling) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.4 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.1->pandas_profiling) (2.5.1)\n",
            "Requirement already satisfied, skipping upgrade: bottleneck in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.1->pandas_profiling) (1.3.2)\n",
            "Collecting multimethod==1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/d0/ce5ad0392aa12645b7ad91a5983d6b625b704b021d9cd48c587630c1a9ac/multimethod-1.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: attrs>=19.3.0 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.1->pandas_profiling) (21.2.0)\n",
            "Requirement already satisfied, skipping upgrade: Pillow; extra == \"type_image_path\" in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.1->pandas_profiling) (7.1.2)\n",
            "Collecting imagehash; extra == \"type_image_path\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/18/9dbb772b5ef73a3069c66bb5bf29b9fb4dd57af0d5790c781c3f559bcca6/ImageHash-4.2.0-py2.py3-none-any.whl (295kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas_profiling) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.11.1->pandas_profiling) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic>=1.8.1->pandas_profiling) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.2.0->pandas_profiling) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.4->visions[type_image_path]==0.7.1->pandas_profiling) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.7.1->pandas_profiling) (1.1.1)\n",
            "Building wheels for collected packages: htmlmin, phik\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp37-none-any.whl size=27085 sha256=138e51723463ead55cfce72a6473317022b71c5488db70cd9b32ccef548d0b61\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "  Building wheel for phik (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for phik: filename=phik-0.11.2-cp37-none-any.whl size=1107413 sha256=cd6cac9f759da5f7450dd17c0f04992131afd3ef1e891321ce35aa686c892850\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/a3/b0/f27b1cfe32ea131a3715169132ff6d85653789e80e966c3bf6\n",
            "Successfully built htmlmin phik\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: phik 0.11.2 has requirement scipy>=1.5.2, but you'll have scipy 1.4.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: htmlmin, PyYAML, phik, requests, tangled-up-in-unicode, multimethod, imagehash, visions, tqdm, pydantic, pandas-profiling\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "Successfully installed PyYAML-5.4.1 htmlmin-0.1.12 imagehash-4.2.0 multimethod-1.4 pandas-profiling-3.0.0 phik-0.11.2 pydantic-1.8.2 requests-2.25.1 tangled-up-in-unicode-0.1.0 tqdm-4.60.0 visions-0.7.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas_profiling",
                  "requests",
                  "yaml"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rznxt7BSRY4b"
      },
      "source": [
        "# 함수 및 실행 전 기초 작업"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo5Nc-bNRjZi"
      },
      "source": [
        "## 1. DB 연결"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0Qa7WURXzsn"
      },
      "source": [
        "\n",
        "### Function **db_connecting_aws**\n",
        "### Function **db_connecting_local**\n",
        "* 매개변수(parameter) : db_name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpOM0M3XRNw3"
      },
      "source": [
        "def db_connecting_aws(db_name):\n",
        "    path = r'/content/gdrive/My Drive/DB 정보/AWS'\n",
        "    f = open(path)\n",
        "    id, pw, host = f.read().split()\n",
        "    db = pymysql.connect(\n",
        "        user = id,\n",
        "        port = 3306,\n",
        "        passwd = pw,\n",
        "        host = host,\n",
        "        db = db_name,\n",
        "        charset = 'utf8',\n",
        "        cursorclass = pymysql.cursors.DictCursor\n",
        "    )\n",
        "    return db\n",
        "    \n",
        "def db_connecting_local(db_name):\n",
        "    path = r'/content/gdrive/My Drive/DB 정보/LOCAL'\n",
        "    f = open(path)\n",
        "    id, pw, host = f.read().split()\n",
        "    db = pymysql.connect(\n",
        "        user = id,\n",
        "        port = 3306,\n",
        "        passwd = pw,\n",
        "        host = host,\n",
        "        db = db_name,\n",
        "        charset = 'utf8',\n",
        "        cursorclass = pymysql.cursors.DictCursor\n",
        "    )\n",
        "    return db"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYOECu0KV_ds"
      },
      "source": [
        "### 실제 DB에 연결하기\n",
        "* cpu의 갯수만큼 연결한다.\n",
        "* 하나로 쓸 db, 여러개로 사용할 db_list를 따로 구성한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69Ktkks_V7vb"
      },
      "source": [
        "#db 작업\n",
        " \n",
        "db = db_connecting_aws('stockdb')\n",
        "\n",
        "db_list_aws = []\n",
        "db_list_local = []\n",
        "num_cores = mp.cpu_count()\n",
        "for _ in range(num_cores):\n",
        "    db_list_aws.append(db_connecting_aws('stockdb'))\n",
        "    db_list_local.append(db_connecting_local('stockdb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fySZcA6CUATn"
      },
      "source": [
        "## 2. Progress_bar 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL3M3_BwYRVe"
      },
      "source": [
        "### Function **my_pbar**\n",
        "* 매개변수(parameter) : value, endvalue, bar_length(default = 20)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQoP4N4KT3Kf"
      },
      "source": [
        "def my_pbar(value, endvalue, bar_length = 20):\n",
        "    if value % 100 == 0 or value == endvalue:\n",
        "        percent = float(value) / endvalue\n",
        "        complete = '<' + '▮' * int(round(percent * bar_length)-1)\n",
        "        remain = '▯' * (bar_length - len(complete)) + '>'\n",
        "        if percent <= 0.33:\n",
        "            color = 91\n",
        "            sys.stdout.write(f\"\\r\\033[{color}m Percent: [{complete+remain}] {round(percent*100,2)}%\\033[0m\")\n",
        "        elif percent <= 0.66:\n",
        "            color = 93\n",
        "            sys.stdout.write(f\"\\r\\033[{color}m Percent: [{complete+remain}] {round(percent*100,2)}%\\033[0m\")\n",
        "        elif percent == 1:\n",
        "            color = 92\n",
        "            sys.stdout.write(f\"\\r\\033[{color}m Percent: [{complete+remain}] {round(percent*100,2)}%\\033[0m\")\n",
        "        else:\n",
        "            color = 96\n",
        "            sys.stdout.write(f\"\\r\\033[{color}m Percent: [{complete+remain}] {round(percent*100,2)}%\\033[0m\")\n",
        "        sys.stdout.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxv_jPo0VJR6"
      },
      "source": [
        "## 3. Manager를 통해 공유메모리 관리하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqygt24iVgZg"
      },
      "source": [
        "num_cores = mp.cpu_count()\n",
        "manager = Manager()\n",
        "db_index = manager.list(list(range(num_cores)))\n",
        "progress = manager.list([0 for x in range(num_cores)])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9Ckn1MMWdUq"
      },
      "source": [
        "## 4. train_data 추출용 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOeioDoJXeHq"
      },
      "source": [
        "### Function **input_making**\n",
        "* 매개변수(parameter) : num\n",
        "> 추출해낼 데이터를 num을 이용하여 랜덤으로 뽑아내기 위한 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Gbya9osXexk"
      },
      "source": [
        "# primary key인 num을 이용하여 추출할 데이터 셋을 랜덤으로 뽑기 위한 함수\n",
        "\n",
        "def input_making(num):\n",
        "    global num_list\n",
        "    index = db_index.pop(0)\n",
        "    db = db_list_aws[index]\n",
        "    sql = f\"\"\"\n",
        "        select \n",
        "            C_code, \n",
        "            DATE_FORMAT(date, '%Y-%m-%d'),\n",
        "            DATE_FORMAT(time, '%H:%i:%s') as time \n",
        "        from mdtbl2 \n",
        "        where num = {num}\n",
        "    \"\"\"\n",
        " \n",
        "    #start_time = dt.datetime.now()\n",
        "    data = pd.read_sql(sql,db)\n",
        "    #print('걸린시간 : %s' %(dt.datetime.now() - start_time))\n",
        " \n",
        "    db_index.append(index)\n",
        "    progress[index] = progress[index] + 1\n",
        "    my_pbar(sum(progress),len(num_list))\n",
        "    if len(data) > 0:\n",
        "        return list(data.values[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hUKExsOWr1D"
      },
      "source": [
        "### Function **data_making**\n",
        "* 매개변수(parameter) : code, date, time\n",
        "> input_making로 뽑아낸 데이터를 이용해 train_data를 추출하는 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRTpqdoFWeCk"
      },
      "source": [
        "# 주어지는 데이터 = code, date, time, db, date_list, input_data\n",
        "# 필요한 데이터 output 값\n",
        "# 최고값 : 1분뒤, 2분뒤, 3분뒤, 5분뒤, 10분뒤, 5분간, 10분간, 20분간, 60분간, 오늘, 1일뒤, 2일뒤, 3일뒤, 5일뒤, 10일뒤, 3일간, 5일간, 10일간, 20일간\n",
        "\n",
        "# 삼성전자를 이용하여 주식이 거래된 날짜의 list를 구한다.\n",
        "sql = \"\"\"\n",
        "    select distinct date from mdtbl2 where C_code = '005930'\n",
        "\"\"\"\n",
        "date_list = pd.read_sql(sql, db)\n",
        "date_list = date_list['date'].tolist()\n",
        "date_list = [str(x) for x in date_list]\n",
        "\n",
        "def data_making(code, date, time):\n",
        "    global input_data\n",
        "    try:\n",
        "        index = db_index.pop(0)\n",
        "        global date_list\n",
        "        date_index = date_list.index(date)\n",
        "        date_min = date_list[date_index - 30] #30일전\n",
        "        date_max = date_list[date_index + 20] #20일후\n",
        "        db = db_list_local[index]\n",
        "        start_time = dt.datetime.now()\n",
        "        sql = f\"\"\"set \n",
        "                    @price = (select priceE from mdtbl2\n",
        "                                where \n",
        "                                    C_code = '{code}' and \n",
        "                                    date = '{date}' and \n",
        "                                    time = '{time}'\n",
        "                            ),\n",
        "                    @price_percent = (select priceE from mdtbl2\n",
        "                                where \n",
        "                                    C_code = '{code}' and \n",
        "                                    date = '{date}' and \n",
        "                                    time = '{time}'\n",
        "                            ) / 100,\n",
        "                    @Issued_shares = (select Issued_shares from ftbl \n",
        "                                        where \n",
        "                                            C_code = '{code}' and \n",
        "                                            dateS <= '{date}' and \n",
        "                                            dateE >= '{date}'\n",
        "                                    ),\n",
        "                    @Issued_shares_minute = (select Issued_shares from ftbl \n",
        "                                        where \n",
        "                                            C_code = '{code}' and \n",
        "                                            dateS <= '{date}' and \n",
        "                                            dateE >= '{date}'\n",
        "                                    ) / 390,\n",
        "                    @BPS = (select BPS from ftbl\n",
        "                                where\n",
        "                                    C_code = '{code}' and\n",
        "                                    dateS <= '{date}' and\n",
        "                                    dateE >= '{date}' \n",
        "                        )\n",
        "            \"\"\"\n",
        "        with db.cursor() as cursor:\n",
        "            cursor.execute(sql)\n",
        "            db.commit() \n",
        "        # 분봉 데이터 가져오기\n",
        "        sql = f\"\"\"\n",
        "            Select\n",
        "                TBL1.C_code as C_code,\n",
        "                (TBL1.PriceS / TBL2.PriceE - 1) * 100 as PriceS,\n",
        "                (TBL1.PriceH / TBL2.PriceE - 1) * 100 as PriceH,\n",
        "                (TBL1.PriceL / TBL2.PriceE - 1) * 100 as PriceL,\n",
        "                (TBL1.PriceE / TBL2.PriceE - 1) * 100 as PriceE,\n",
        "                TBL1.trade as Trade\n",
        "\n",
        "                from\n",
        "                (\n",
        "                select\n",
        "                    C_code,\n",
        "                    date, \n",
        "                    time,\n",
        "                    PriceS,\n",
        "                    PriceH,\n",
        "                    PriceL,\n",
        "                    PriceE, \n",
        "                    trade / @Issued_shares_minute as trade\n",
        "                    from mdtbl2\n",
        "                    where\n",
        "                        C_code = '{code}' and\n",
        "                        date = '{date}' and\n",
        "                        time > Date_SUB(time('{time}'), interval 60 minute) and\n",
        "                        time <= '{time}'\n",
        "                ) as TBL1,\n",
        "\n",
        "                (\n",
        "                select\n",
        "                    C_code, \n",
        "                    date,\n",
        "                    Date_ADD(time, interval 1 minute) as time,\n",
        "                    PriceE\n",
        "                    from mdtbl2\n",
        "                    where\n",
        "                        C_code = '{code}' and\n",
        "                        (\n",
        "                            (\n",
        "                            date = '{date}' and\n",
        "                            time > Date_SUB(time('{time}'), interval 61 minute) and\n",
        "                            time < '{time}'\n",
        "                            )\n",
        "                            or\n",
        "                            (\n",
        "                            date = '{date_list[date_index - 1]}' and\n",
        "                            time = '15:30:00'\n",
        "                            )\n",
        "\n",
        "                        )\n",
        "                ) as TBL2\n",
        "                where\n",
        "                    TBL1.C_code = TBL2.C_code and\n",
        "                    (\n",
        "                        (\n",
        "                        TBL1.date = TBL2.date and\n",
        "                        TBL1.time = TBL2.time\n",
        "                        )\n",
        "                        or\n",
        "                        (\n",
        "                        TBL1.date = Date_ADD(TBL2.date, interval 1 day) and\n",
        "                        TBL1.time = '09:00:00'\n",
        "                        )\n",
        "                    )\n",
        "                    \n",
        "        \"\"\"\n",
        "    \n",
        "        df_input_M = pd.read_sql(sql,db)\n",
        "        # 일봉 데이터 가져오기\n",
        "    \n",
        "        time_list = [1,2,3,5,10]\n",
        "        date_30B = date_list[date_index - 30] #30일전\n",
        "    \n",
        "        sql = f\"\"\"\n",
        "            select \n",
        "                TBL1.C_code as C_code, \n",
        "                TBL1.priceS / @BPS as priceS, \n",
        "                TBL1.priceH / @BPS as priceH, \n",
        "                TBL1.priceL / @BPS as priceL, \n",
        "                TBL2.priceE / @BPS as priceE, \n",
        "                TBL1.trade / @Issued_shares as trade\n",
        "                from (\n",
        "                    select \n",
        "                        C_code, \n",
        "                        date, \n",
        "                        time, \n",
        "                        priceS, \n",
        "                        max(priceH) as priceH, \n",
        "                        min(priceL) as priceL, \n",
        "                        sum(trade) as trade \n",
        "                    from mdtbl2\n",
        "                    where\n",
        "                        C_code = '{code}'and\n",
        "                        date < '{date}' and\n",
        "                        date >= '{date_30B}'\n",
        "                    group by C_code, date\n",
        "                    ) as TBL1,\n",
        "    \n",
        "                    (\n",
        "                    select C_code, date, priceE \n",
        "                    from mdtbl2\n",
        "                    where \n",
        "                        C_code = '{code}'and\n",
        "                        date < '{date}' and\n",
        "                        date >= '{date_30B}' and\n",
        "                        time = '15:30:00'\n",
        "                    ) as TBL2\n",
        "                where TBL1.C_code = TBL2.C_code and TBL1.date = TBL2.date\n",
        "        \"\"\"\n",
        "        df_input_D = pd.read_sql(sql, db)\n",
        "    \n",
        "        #output 가져오기\n",
        "        dates = [1,2,3,5,10,20]\n",
        "        tmp_date = [date_list[date_index + x] for x in dates]\n",
        "    \n",
        "    \n",
        "        sql = f\"\"\"\n",
        "            select \n",
        "                (TBL1.priceH - @price) / @price_percent as AF_1M,\n",
        "                (TBL2.priceH - @price) / @price_percent as AF_2M,\n",
        "                (TBL3.priceH - @price) / @price_percent as AF_3M,\n",
        "                (TBL4.priceH - @price) / @price_percent as AF_5M,\n",
        "                (TBL5.priceH - @price) / @price_percent as AF_10M,\n",
        "                (TBL6.priceH - @price) / @price_percent as Max_5M,\n",
        "                (TBL7.priceH - @price) / @price_percent as Max_10M,\n",
        "                (TBL8.priceH - @price) / @price_percent as Max_20M,\n",
        "                (TBL9.priceH - @price) / @price_percent as Max_60M,\n",
        "                (TBL10.priceH - @price) / @price_percent as Max_Today,\n",
        "                (TBL11.priceH - @price) / @price_percent as Max_AF_1D,\n",
        "                (TBL12.priceH - @price) / @price_percent as Max_AF_2D,\n",
        "                (TBL13.priceH - @price) / @price_percent as Max_AF_3D,\n",
        "                (TBL14.priceH - @price) / @price_percent as Max_AF_5D,\n",
        "                (TBL15.priceH - @price) / @price_percent as Max_AF_10D,\n",
        "                (TBL16.priceH - @price) / @price_percent as Max_3D,\n",
        "                (TBL17.priceH - @price) / @price_percent as Max_5D,\n",
        "                (TBL18.priceH - @price) / @price_percent as Max_10D,\n",
        "                (TBL19.priceH - @price) / @price_percent as Max_20D\n",
        "            from (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where \n",
        "                    C_code = '{code}' and \n",
        "                    date = '{date}' and \n",
        "                    time = Date_Add(time('{time}'), interval 1 minute)\n",
        "            ) as TBL1,\n",
        "            \n",
        "            (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where \n",
        "                    C_code = '{code}' and \n",
        "                    date = '{date}' and \n",
        "                    time = Date_Add(time('{time}'), interval 2 minute)\n",
        "            ) as TBL2,\n",
        "            \n",
        "            (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where \n",
        "                    C_code = '{code}' and \n",
        "                    date = '{date}' and \n",
        "                    time = Date_Add(time('{time}'), interval 3 minute)\n",
        "            ) as TBL3,\n",
        "            \n",
        "            (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where \n",
        "                    C_code = '{code}' and \n",
        "                    date = '{date}' and \n",
        "                    time = Date_Add(time('{time}'), interval 5 minute)\n",
        "            ) as TBL4,\n",
        "            \n",
        "            (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where \n",
        "                    C_code = '{code}' and \n",
        "                    date = '{date}' and \n",
        "                    time = Date_Add(time('{time}'), interval 10 minute)\n",
        "            ) as TBL5,\n",
        "    \n",
        "            (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where \n",
        "                    C_code = '{code}' and \n",
        "                    date = '{date}' and \n",
        "                    time > '{time}' and\n",
        "                    time <= Date_Add(time('{time}'), interval 5 minute)\n",
        "            ) as TBL6,\n",
        "    \n",
        "            (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where\n",
        "                    C_code = '{code}' and \n",
        "                    date = '{date}' and \n",
        "                    time > '{time}' and\n",
        "                    time <= Date_Add(time('{time}'), interval 10 minute)\n",
        "            ) as TBL7,\n",
        "    \n",
        "            (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where \n",
        "                    C_code = '{code}' and \n",
        "                    date = '{date}' and \n",
        "                    time > '{time}' and\n",
        "                    time <= Date_Add(time('{time}'), interval 20 minute)\n",
        "            ) as TBL8,\n",
        "    \n",
        "            (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where \n",
        "                    C_code = '{code}' and \n",
        "                    date = '{date}' and \n",
        "                    time > '{time}' and\n",
        "                    time <= Date_Add(time('{time}'), interval 60 minute)\n",
        "            ) as TBL9,\n",
        "            \n",
        "            (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where \n",
        "                    C_code = '{code}' and \n",
        "                    date = '{date}' and \n",
        "                    time >= '{time}'\n",
        "            ) as TBL10,\n",
        "            \n",
        "            (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where \n",
        "                    C_code = '{code}' and \n",
        "                    date = '{tmp_date[0]}'\n",
        "            ) as TBL11,\n",
        "            \n",
        "            (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where \n",
        "                    C_code = '{code}' and \n",
        "                    date = '{tmp_date[2]}'\n",
        "            ) as TBL12,\n",
        "            \n",
        "            (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where \n",
        "                    C_code = '{code}' and \n",
        "                    date = '{tmp_date[3]}'\n",
        "            ) as TBL13,\n",
        "            \n",
        "            (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where \n",
        "                    C_code = '{code}' and \n",
        "                    date = '{tmp_date[4]}'\n",
        "            ) as TBL14,\n",
        "            \n",
        "            (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where \n",
        "                    C_code = '{code}' and \n",
        "                    date ='{tmp_date[5]}'\n",
        "            ) as TBL15,\n",
        "            \n",
        "            (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where \n",
        "                    C_code = '{code}' and \n",
        "                    date > '{date}' and\n",
        "                    date <= '{tmp_date[2]}'\n",
        "            ) as TBL16,\n",
        "            \n",
        "            (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where \n",
        "                    C_code = '{code}' and \n",
        "                    date > '{date}' and\n",
        "                    date <= '{tmp_date[3]}'\n",
        "            ) as TBL17,\n",
        "            \n",
        "            (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where \n",
        "                    C_code = '{code}' and \n",
        "                    date > '{date}' and\n",
        "                    date <= '{tmp_date[4]}'\n",
        "            ) as TBL18,\n",
        "            \n",
        "            (\n",
        "                select ifnull(max(priceH),0) as priceH\n",
        "                from mdtbl2\n",
        "                where \n",
        "                    C_code = '{code}' and \n",
        "                    date > '{date}' and\n",
        "                    date <= '{tmp_date[5]}'\n",
        "            ) as TBL19\n",
        "        \"\"\"\n",
        "    \n",
        "    \n",
        "        df_output = pd.read_sql(sql, db)\n",
        "    \n",
        "        df_list = [df_input_M,df_input_D,df_output]\n",
        "        return df_list\n",
        "    except:\n",
        "        pass\n",
        "    finally:\n",
        "        #print('걸린시간 : %s' %(dt.datetime.now() - start_time))\n",
        "        db_index.append(index)\n",
        "        progress[index] = progress[index] + 1\n",
        "        my_pbar(sum(progress),len(input_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bGaQVjtYcG3"
      },
      "source": [
        "### Function **minute_frame**\n",
        "* 매개변수(parameter) : df, column_num_M\n",
        "> data_making으로 뽑아낸 데이터를 정규화 해주는 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTOdr51hYwof"
      },
      "source": [
        "def minute_frame(df,column_num_M):\n",
        "    ary = np.zeros((60,column_num_M), dtype = object)\n",
        "    data_len = len(df)\n",
        "    ary[60-data_len:,:] = df\n",
        "\n",
        "    return ary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r1HO2XiYsyn"
      },
      "source": [
        "### Function **day_frame**\n",
        "* 매개변수(parameter) : df, column_num_D\n",
        "> data_making으로 뽑아낸 데이터를 정규화 해주는 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnjfUEmoYxwu"
      },
      "source": [
        "def day_frame(df,column_num_D):\n",
        "    ary = np.zeros((30,column_num_D), dtype = object)\n",
        "    data_len = len(df)\n",
        "    ary[30-data_len:,:] = df\n",
        "\n",
        "    return ary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN5jNWAQZZj-"
      },
      "source": [
        "# 실제 데이터 추출"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0MWiqzYZod7"
      },
      "source": [
        "## input_data 추출\n",
        "* multiprocessing을 이용하여 데이터를 빠르게 추출한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nInfmSHWbrBg"
      },
      "source": [
        "### process 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OczpBxG4btXv"
      },
      "source": [
        "pool = Pool(num_cores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1K4um_abzTX"
      },
      "source": [
        "### max_num까지 30만개 뽑기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvWsVOOmb1XO"
      },
      "source": [
        "sql = '''\n",
        "    select max(num) as num from mdtbl2\n",
        "'''\n",
        "max_num = pd.read_sql(sql,db)['num'][0]\n",
        "num_list = random.sample(range(1,max_num),300000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIg80BrJb4P2"
      },
      "source": [
        "### input_data 추출하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muVgkWlOb4Vt"
      },
      "source": [
        "start_time = dt.datetime.now()\n",
        "progress = manager.list([0 for x in range(num_cores)])\n",
        "input_data = pool.map(input_making, num_list)\n",
        "my_pbar(100,100)\n",
        "progress = manager.list([0 for x in range(num_cores)])\n",
        "print('총 걸린시간 : %s' %(dt.datetime.now() - start_time))\n",
        "total = len(input_data)\n",
        "input_data = list(filter(None, input_data))\n",
        "dummy = total - len(input_data)\n",
        "print(f'None값을 가진 데이터 {dummy}개를 제외하고, 총 {len(input_data)}개의 데이터 추출')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsQ6z_Rjb_bk"
      },
      "source": [
        "#### date기준 필터링\n",
        "* 현재까지 수집해둔 데이터(mysql에 들어있는)가 2020년 1월 ~ 2021년 1월 즈음으로, 모든 데이터를 이용하기에는 무리가 있어 해당 날짜의 input_data만 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "QYRCfJ9TZsrd",
        "outputId": "c1130616-7b5a-40f0-b251-3ae649ab25ce"
      },
      "source": [
        "start_date = dt.datetime.strptime('2020-02-20', '%Y-%m-%d')\n",
        "end_date = dt.datetime.strptime('2020-11-20', '%Y-%m-%d')\n",
        "input_data = [x for x in input_data if (dt.datetime.strptime(x[1], '%Y-%m-%d') >= start_date and dt.datetime.strptime(x[1], '%Y-%m-%d') <= end_date)]\n",
        "print(f'현재 가진 데이터로는 추출 불가능한 데이터 {total - dummy - len(input_data)}개를 제외하고, 총 {len(input_data)}개의 데이터 추출')\n",
        "\n",
        "pool.close()\n",
        "pool.join()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-312c75b39c3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# process 만들기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m sql = '''\n\u001b[1;32m      4\u001b[0m     \u001b[0mselect\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmdtbl2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m '''\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_cores' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6kb4khIcEHs"
      },
      "source": [
        "## train_data 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB0IiC-2cLBC"
      },
      "source": [
        "num_cores = mp.cpu_count()\n",
        " \n",
        "pool = Pool(num_cores) # process 만들기\n",
        " \n",
        "start_time = dt.datetime.now()\n",
        "train_data = pool.starmap(data_making, input_data)\n",
        "my_pbar(100,100)\n",
        "train_data = list(filter(None, train_data))\n",
        "print('총 걸린시간 : %s' %(dt.datetime.now() - start_time))\n",
        "pool.close()\n",
        "pool.join()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihJLdXuncPUI"
      },
      "source": [
        "## train_data 정규화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAMgFXmmZlRZ"
      },
      "source": [
        "column_num_M = len(train_data[0][0].transpose())\n",
        "column_num_D = len(train_data[0][1].transpose())\n",
        "\n",
        "#60분 동안의 데이터를 수집할 것이기 떄문에, 60으로 설정\n",
        "\n",
        "train_data_M = [minute_frame(x[0],column_num_M) for x in train_data]\n",
        "train_data_D = [day_frame(x[1],column_num_D) for x in train_data]\n",
        "train_data_Out = [x[2] for x in train_data]\n",
        "\n",
        "train_ary_M = np.stack(train_data_M, axis = 0)\n",
        "train_ary_D = np.stack(train_data_D, axis = 0)\n",
        "train_ary_Out = np.stack(train_data_Out, axis = 0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFntc1Mqcg1Y"
      },
      "source": [
        "## numpy파일로 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naM_PzsrchxK"
      },
      "source": [
        "path = r'/content/gdrive/My Drive/인공지능 데이터/'\n",
        "\n",
        "np.save(path + '60분데이터',train_ary_M)\n",
        "np.save(path + '30일데이터',train_ary_D)\n",
        "np.save(path + '결과데이터',train_ary_Out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_Hy7NMRco6u"
      },
      "source": [
        "# dd"
      ]
    }
  ]
}